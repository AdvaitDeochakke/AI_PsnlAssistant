{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      "Please speak now...\n"
     ]
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "import speech_recognition as sr\n",
    "import os\n",
    "from playsound import playsound\n",
    "import time\n",
    "import openai\n",
    "import weaviate\n",
    "import json\n",
    "import requests\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "    \n",
    "\n",
    "# List available üê∏TTS models and choose the first one\n",
    "model_name = 'tts_models/en/ljspeech/tacotron2-DDC'\n",
    "# considering switchign to pytts3x\n",
    "\n",
    "# Init TTS\n",
    "tts = TTS(model_name)\n",
    "\n",
    "# Create a recognizer object\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Prompt the user to speak\n",
    "print(\"Please speak now...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "playsound(os.path.join(os.getcwd(), 'please_speak.wav'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    }
   ],
   "source": [
    "with sr.Microphone() as source:\n",
    "    audio = r.listen(source)\n",
    "print(\"Processing...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "playsound(os.path.join(os.getcwd(), 'ipt_recv.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your text input is  how is the weather in Chennai\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Convert speech to text\n",
    "    text = r.recognize_google(audio)\n",
    "    # text = \"got that promotion at work! üéâüôåüèº But at what cost üòîüíî\"\n",
    "    #text = \"What does Assorted really mean? I see it in a box of chocolates being represented as a varied collection, but other times I see it as many items of the same quality and such?\"\n",
    "\n",
    "except sr.UnknownValueError:\n",
    "    playsound(os.path.join(os.getcwd(), 'unable_to_understand.wav')) \n",
    "\n",
    "print(\"Your text input is \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input prompt is\n",
      "\n",
      "What are the keywords or phrases from the sentence :\n",
      "how is the weather in Chennai\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# alright crazy idea\n",
    "# instead of some bigass RAKE up my codebase or doing logn NLTK stuff\n",
    "# what if i just .... \n",
    "# use openAI for keyword extraction?????\n",
    "# god i may be a genius (re: Sarcasm)\n",
    "# text = \"Who are the legendary Vampire Counts of the Von Carstein bloodline?\"\n",
    "input_prompt = \"\"\"\n",
    "What are the keywords or phrases from the sentence :\n",
    "\"\"\"+text+\"\\nOutput:\"\n",
    "print(\"The input prompt is\")\n",
    "print(input_prompt)\n",
    "# input_prompt = \"\"\"\n",
    "# Classify tweet as positive, negative, or neutral\n",
    "# (Take into account hidden meaning of emojis, and meme culture context): \n",
    "# \"\"\" + text + \"\\nOutput:\"\n",
    "# print(input_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get('OPENAI_APIKEY')\n",
    "openai.api_key = api_key\n",
    "# shifting model to 3.5 turbo, saves SOO many tokens\n",
    "# also chat completion instead of simple completion\n",
    "# already trained, just need to piepline\n",
    "GPT_MODEL = \"gpt-3.5-turbo-0613\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather, Chennai\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=GPT_MODEL,\n",
    "  messages=[\n",
    "    {\"role\" : \"system\", \"content\" : \"You are to find upto 3 keywords or keyphrases from a given sentence\"},\n",
    "    {\"role\" : \"system\", \"content\" : \"Restrict yourself to ONLY provide the answer, and nothing else\"},\n",
    "    {\"role\" : \"system\", \"content\" : \"Provide the response as a list of words which are comma separated\"},\n",
    "    {\"role\" : \"user\", \"content\" : input_prompt},\n",
    "  ]\n",
    ")\n",
    "\n",
    "keyphrases = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "print(keyphrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy for db/context access\n",
    "# split keywords across ,\n",
    "# strip spaces\n",
    "# search context db for keyword\n",
    "# add context (if found) to the input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate_client_url = \"http://localhost:8080\"\n",
    "\n",
    "# docker-compose up -d <- to create\n",
    "# docker-compose start <- to start\n",
    "# docker-compose down <- to remove and exit\n",
    "# docker-compose stop <- to stop\n",
    "\n",
    "client = weaviate.Client(\n",
    "    url=weaviate_client_url,  # Replace with your endpoint\n",
    "    additional_headers={\n",
    "        \"X-OpenAI-Api-Key\": api_key  # Or \"X-Cohere-Api-Key\" or \"X-HuggingFace-Api-Key\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# some_objects = client.data_object.get()\n",
    "# # print(json.dumps(some_objects))\n",
    "# print(\"Article title  : \" + some_objects['objects'][0]['properties']['title'])\n",
    "# print(\"Article sample : \" + some_objects['objects'][0]['properties']['content'][0:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weather', 'Chennai']\n",
      "Title : Chennai Content :\n",
      "Chennai (formerly known as Madras) is the capital city of the Indian state of Tamil Nadu\n",
      " It has a population of about 7 million people\n",
      "\n",
      "\n",
      "For keyword : weather\n",
      "Title : National Weather Service \n",
      "Content :\n",
      "The National Weather Service (also known as NWS) is one of the six scientific agencies that make up the National Oceanic and Atmospheric Administration (NOAA) of the United States government\n",
      " Its job is to provide \"weather, hydrologic, and climate forecasts and warnings for the United States, its territories, adjacent waters and ocean areas, for the protection of life and property and the enhancement of the national economy\n",
      "\n",
      "\n",
      "For keyword : Chennai\n",
      "Context Below -> \n",
      "Chennai\n",
      "Chennai (formerly known as Madras) is the capital city of the Indian state of Tamil Nadu\n",
      " It has a population of about 7 million people\n",
      "\n",
      "National Weather Service\n",
      "The National Weather Service (also known as NWS) is one of the six scientific agencies that make up the National Oceanic and Atmospheric Administration (NOAA) of the United States government\n",
      " Its job is to provide \"weather, hydrologic, and climate forecasts and warnings for the United States, its territories, adjacent waters and ocean areas, for the protection of life and property and the enhancement of the national economy\n",
      "\n",
      "<- Context Above\n"
     ]
    }
   ],
   "source": [
    "contents = list()\n",
    "title = list()\n",
    "# keywords = [\"Hitler\", \"Xianxia\", \"wallet\"]\n",
    "context = \"Context Below -> \"\n",
    "keywords = keyphrases.split(\",\")\n",
    "keywords = [word.strip() for word in keywords]\n",
    "\n",
    "print(keywords)\n",
    "\n",
    "\n",
    "nearText = {\"concepts\" : text}\n",
    "nearResponse = (\n",
    "    client.query\n",
    "    .get(\"Article\", [\"title\", \"content\"])\n",
    "    .with_near_text(nearText)\n",
    "    .with_limit(1)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "wiki_content = nearResponse['data']['Get']['Article'][0]['content']\n",
    "lines = wiki_content.split('.')\n",
    "\n",
    "wiki_title = nearResponse['data']['Get']['Article'][0]['title']\n",
    "context = context + \"\\n\" + wiki_title + \"\\n\"\n",
    "\n",
    "print(\"Title :\", wiki_title, \"Content :\")\n",
    "for line in lines[0:2]:\n",
    "    if line == \"\":\n",
    "        break\n",
    "    context = context + line + \"\\n\"\n",
    "    print(line)\n",
    "print(\"\\n\")\n",
    "\n",
    "for keyword in keywords:\n",
    "    print(\"For keyword :\", keyword)\n",
    "    response = (\n",
    "        client.query\n",
    "        .get(\"Article\", [\"title\", \"content\"])\n",
    "        .with_hybrid(keyword, alpha=0.5)  # default 0.75\n",
    "        .with_limit(1)\n",
    "        .do()\n",
    "    )\n",
    "    \n",
    "    if response == nearResponse:\n",
    "        continue\n",
    "\n",
    "    wiki_content = response['data']['Get']['Article'][0]['content']\n",
    "    lines = wiki_content.split('.')\n",
    "    \n",
    "    wiki_title = response['data']['Get']['Article'][0]['title']\n",
    "    context = context + \"\\n\" + wiki_title + \"\\n\"\n",
    "    \n",
    "    print(\"Title :\", wiki_title, \"\\nContent :\")\n",
    "    for line in lines[0:2]:\n",
    "        # print(\"len of line is \", len(line))\n",
    "        if line[0] == \"\\n\":\n",
    "            # print(\"entered inside\")\n",
    "            break\n",
    "        context = context + line + \"\\n\"\n",
    "        print(line)\n",
    "    print(\"\\n\")\n",
    "context = context + \"\\n<- Context Above\"\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context = \"\"\"\n",
    "# Vampire\n",
    "# Vampires are monsters in legends and stories\n",
    "#  The first vampire stories were told in Eastern Europe, but much of how modern people see vampires was created by Bram Stoker in the famous novel, Dracula\n",
    "\n",
    "# Vampire bat\n",
    "# Vampire bats is a subfamily of bats\n",
    "#  Unlike other bats, vampire bats feed on blood\n",
    "\n",
    "# Warhammer 40,000\n",
    "# Warhammer 40,000 , also called 40k, is a table-top game and fictional setting made by Games Workshop, in which model armies fight against each other on miniature terrain\n",
    "\n",
    "# Bismarck\n",
    "# Bismarck is a German family name\n",
    "#  Bismark is an incorrect spelling\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The input prompt is\n",
      "how is the weather in Chennai\n",
      "\n",
      "GPT Instructions:\n",
      "\n",
      "You are a personal assistant. Your job is to answer the user queries.\n",
      "You will be provided some additional info, and have to decide if info is relevant to the query.\n",
      "The user is unaware of the info provided, and do not refer the existence of this info in your answer\n",
      "\n",
      "Context is given as:\n",
      "Context Below -> \n",
      "Chennai\n",
      "Chennai (formerly known as Madras) is the capital city of the Indian state of Tamil Nadu\n",
      " It has a population of about 7 million people\n",
      "\n",
      "National Weather Service\n",
      "The National Weather Service (also known as NWS) is one of the six scientific agencies that make up the National Oceanic and Atmospheric Administration (NOAA) of the United States government\n",
      " Its job is to provide \"weather, hydrologic, and climate forecasts and warnings for the United States, its territories, adjacent waters and ocean areas, for the protection of life and property and the enhancement of the national economy\n",
      "\n",
      "<- Context Above\n"
     ]
    }
   ],
   "source": [
    "# text = \"sample text, Hi Who Are You?\"\n",
    "# context = \"sample context, Himeko from Honkai Impact\"\n",
    "\n",
    "# do i need a 'personality' ??\n",
    "# or is the default fine?\n",
    "# im kinda not making a neuro-mini anymore\n",
    "# just doing my own thing\n",
    "# remind myself -> rethink personality inputs\n",
    "\n",
    "personality = \"\"\"\n",
    "You are a personal assistant. Your job is to answer the user queries.\n",
    "You will be provided some additional info, and have to decide if info is relevant to the query.\n",
    "The user is unaware of the info provided, and do not refer the existence of this info in your answer\"\"\"\n",
    "user_prompt = text\n",
    "\n",
    "print(\"\\nThe input prompt is\")\n",
    "print(user_prompt)\n",
    "print(\"\\nGPT Instructions:\")\n",
    "print(personality)\n",
    "print(\"\\nContext is given as:\")\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city, eg. San Francisco, or Chennai\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    }]\n",
    "\n",
    "def get_current_weather(location):\n",
    "    # print(\"test\")\n",
    "    # print(location)\n",
    "    # print(format)\n",
    "    api_key = os.environ.get('weather_api_key')\n",
    "    base_url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
    "    complete_url = base_url + \"appid=\" + api_key + \"&q=\" + location\n",
    "    response = requests.get(complete_url)\n",
    "    x = response.json()\n",
    "    if x[\"cod\"] != \"404\":\n",
    "        y = x[\"main\"]\n",
    "        current_temperature = y[\"temp\"]\n",
    "        z = x['weather']\n",
    "        weather_description = z[0][\"description\"]\n",
    "        return (\"temp is \"+str(round(current_temperature-273.15, 2))+\" and weather is \"+str(weather_description))\n",
    "\n",
    "function_exec = {\n",
    "    'get_current_weather' : get_current_weather\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_response = openai.ChatCompletion.create(\n",
    "  model=GPT_MODEL,\n",
    "  messages=[\n",
    "    {\"role\" : \"system\", \"content\" : personality+context},\n",
    "    {\"role\" : \"user\", \"content\" : user_prompt}\n",
    "  ],\n",
    "  functions=functions\n",
    ")\n",
    "# choices = query_response['choices'][0]\n",
    "# finish = choices['finish_reason']\n",
    "# if finish == 'function_call':\n",
    "#   function_exec[choices['message']['function_call']]()\n",
    "\n",
    "# answer = query_response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_current_weather\n",
      "{\n",
      "  \"location\": \"Chennai\"\n",
      "}\n",
      "func inputs full {'location': 'Chennai'}\n",
      "location Chennai\n",
      "temp is 34.98 and weather is few clouds\n"
     ]
    }
   ],
   "source": [
    "# print(query_response['choices'][0]['finish_reason'])\n",
    "# finish = query_response['choices'][0]['finish_reason']\n",
    "# if finish == 'function_call':\n",
    "#   print(\"test\")\n",
    "print(query_response['choices'][0]['message']['function_call']['name'])\n",
    "print(query_response['choices'][0]['message']['function_call']['arguments'])\n",
    "\n",
    "choices = query_response['choices'][0]\n",
    "finish = choices['finish_reason']\n",
    "if finish == 'function_call':\n",
    "  func_params = choices['message']['function_call']\n",
    "  func_name = func_params['name']\n",
    "  func_inputs = json.loads(func_params['arguments'])\n",
    "  print(\"func inputs full\", func_inputs)\n",
    "  print(\"location\", func_inputs.get('location'))\n",
    "  output = function_exec[choices['message']['function_call']['name']](func_inputs.get(\"location\"))\n",
    "  print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m sentences \u001b[39min\u001b[39;00m answer\u001b[39m.\u001b[39;49msplit(\u001b[39m\"\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(sentences)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "for sentences in answer.split(\". \"):\n",
    "    print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the pytts3x for synthing\n",
    "import pyttsx3\n",
    "tester_engine = pyttsx3.init()\n",
    "tester_engine.setProperty('rate', 175)\n",
    "tester_engine.setProperty('voice', tester_engine.getProperty('voices')[1].id)\n",
    "tester_engine.say(answer)\n",
    "tester_engine.runAndWait()\n",
    "tester_engine.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run TTS on the text\n",
    "# tts.tts_to_file(reply, file_path='output.wav')\n",
    "# second idea, can i maybe stream RVC through this?\n",
    "# or SOVITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken :  28.53394913673401\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "# import playsound\n",
    "# import os\n",
    "# playsound(os.path.join(os.getcwd(), 'output.wav'))\n",
    "\n",
    "print(\"time taken : \", -start_time + end_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
